# ğŸ›’ E-commerce Price Prediction Pipeline

This project is an **end-to-end ML Engineering pipeline** for predicting product prices using **web crawled data** from e-commerce websites.  
The pipeline is fully automated with **Apache Airflow**, starting from data crawling to model training.

---

## ğŸ“‚ Project Structure
```
ecommerce_price_prediction/
â”‚â”€â”€ dags/
â”‚ â””â”€â”€ ecommerce_pipeline.py # Airflow DAG
â”‚â”€â”€ src/
â”‚ â”œâ”€â”€ crawler.py # Web crawler (scrapes product data)
â”‚ â”œâ”€â”€ preprocess.py # Data cleaning & preprocessing
â”‚ â”œâ”€â”€ feature_engineering.py # Feature creation
â”‚ â””â”€â”€ train_model.py # Model training
â”‚â”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Raw crawled data
â”‚ â””â”€â”€ processed/ # Cleaned & feature-engineered data
â”‚â”€â”€ models/
â”‚ â””â”€â”€ price_predictor.pkl # Trained ML model
â”‚â”€â”€ requirements.txt # Dependencies
```


---

## âš™ï¸ Workflow

```mermaid
flowchart TD
    A[Web Crawler] --> B[Raw Data Storage]
    B --> C[Preprocessing]
    C --> D[Feature Engineering]
    D --> E[Model Training]
    E --> F[Model Registry]
```

Step 1 â€“ Crawler: Collects product data (title, price, rating) from an e-commerce website.

Step 2 â€“ Preprocessing: Cleans missing values, converts prices, and normalizes data.

Step 3 â€“ Feature Engineering: Creates additional features (e.g., rating score, price bucket).

Step 4 â€“ Model Training: Trains a RandomForestRegressor to predict product prices.

Step 5 â€“ Deployment (future work): Serve predictions via API (FastAPI/Flask).

# ğŸš€ Getting Started
1ï¸âƒ£ Clone Repository
```
git clone https://github.com/your-username/Ecommerce-web_crowler.git
cd Ecommerce-web_crowler
```

---

2ï¸âƒ£ Create Virtual Environment
```
python -m venv venv
source venv/bin/activate   # Linux / Mac
venv\Scripts\activate      # Windows
```

---

3ï¸âƒ£ Install Dependencies
```
pip install -r requirements.txt
```

---

4ï¸âƒ£ Run Each Script Individually
```
python scripts/crawler.py
python scripts/preprocess.py
python scripts/feature_engineering.py
python scripts/train_model.py
```

---

5ï¸âƒ£ Run with Airflow

Start Airflow webserver and scheduler:
```
airflow db init
airflow webserver --port 8080
airflow scheduler
```

---

# Place ecommerce_pipeline.py inside dags/ folder.
Open http://localhost:8080 and trigger the DAG.

---
# ğŸ“Š Example Output
Raw data: data/raw/products_YYYYMMDD.csv

Processed data: data/processed/cleaned_data.csv

Feature data: data/processed/features.csv

Trained model: models/price_predictor.pkl

---

# ğŸ› ï¸ Tech Stack

Python 3.9+

BeautifulSoup4 â€“ Web scraping

Pandas â€“ Data processing

Scikit-learn â€“ Model training

Joblib â€“ Model saving

Apache Airflow â€“ Workflow orchestration

---

# ğŸ”® Future Improvements

Deploy trained model with FastAPI or Flask

Store crawled data in PostgreSQL / S3 / Delta Lake

Add MLflow for model versioning

Implement real-time price monitoring

---

# ğŸ‘¨â€ğŸ’» Author

Diyorbek Fozilov
ML Engineer | Data Scientist
ğŸ“§ Email: diyorbekfozilov011@gmail.com

ğŸŒ LinkedIn
 | GitHub
